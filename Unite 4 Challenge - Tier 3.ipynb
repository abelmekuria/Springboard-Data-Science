{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 48)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First off, let's use .shape feature of pandas DataFrames to look at the number of rows and columns. \n",
    "properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>72514.7</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-02-01</th>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>73155.2</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-03-01</th>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>72190.4</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-01</th>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>71442.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City of London Barking & Dagenham     Barnet     Bexley      Brent  \\\n",
       "NaT             E09000001          E09000002  E09000003  E09000004  E09000005   \n",
       "1995-01-01          91449            50460.2    93284.5    64958.1    71306.6   \n",
       "1995-02-01        82202.8            51085.8    93190.2    64787.9    72022.3   \n",
       "1995-03-01        79120.7              51269    92247.5    64367.5    72015.8   \n",
       "1995-04-01        77101.2            53133.5    90762.9    64277.7    72965.6   \n",
       "\n",
       "              Bromley     Camden    Croydon     Ealing    Enfield    ...      \\\n",
       "NaT         E09000006  E09000007  E09000008  E09000009  E09000010    ...       \n",
       "1995-01-01    81671.5     120933    69158.2    79885.9    72514.7    ...       \n",
       "1995-02-01    81657.6     119509    68951.1    80897.1    73155.2    ...       \n",
       "1995-03-01    81449.3     120282    68712.4    81379.9    72190.4    ...       \n",
       "1995-04-01    81124.4     120098      68610    82188.9    71442.9    ...       \n",
       "\n",
       "           NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS  \\\n",
       "NaT         E12000002          E12000003     E12000004     E12000005   \n",
       "1995-01-01    43958.5            44803.4       45544.5       48527.5   \n",
       "1995-02-01    43925.4            44528.8       46051.6       49341.3   \n",
       "1995-03-01    44434.9            45200.5       45383.8       49442.2   \n",
       "1995-04-01    44267.8            45614.3       46124.2       49455.9   \n",
       "\n",
       "           EAST OF ENGLAND     LONDON SOUTH EAST SOUTH WEST Unnamed: 46  \\\n",
       "NaT              E12000006  E12000007  E12000008  E12000009         NaN   \n",
       "1995-01-01         56701.6    74435.8    64018.9    54705.2         NaN   \n",
       "1995-02-01         56593.6    72777.9      63715    54356.1         NaN   \n",
       "1995-03-01         56171.2    73896.8    64113.6    53583.1         NaN   \n",
       "1995-04-01         56567.9    74455.3    64623.2      54786         NaN   \n",
       "\n",
       "              England  \n",
       "NaT         E92000001  \n",
       "1995-01-01    53202.8  \n",
       "1995-02-01    53096.2  \n",
       "1995-03-01    53201.3  \n",
       "1995-04-01    53590.9  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the .head() method, let's check out the state of our dataset.  \n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [],
   "source": [
    "# Do this here\n",
    "properties_T = properties.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>1995-09-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>104473</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>51471.6</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>93273.1</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>64509.5</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>73789.5</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          NaT 1995-01-01 1995-02-01 1995-03-01 1995-04-01  \\\n",
       "City of London      E09000001      91449    82202.8    79120.7    77101.2   \n",
       "Barking & Dagenham  E09000002    50460.2    51085.8      51269    53133.5   \n",
       "Barnet              E09000003    93284.5    93190.2    92247.5    90762.9   \n",
       "Bexley              E09000004    64958.1    64787.9    64367.5    64277.7   \n",
       "Brent               E09000005    71306.6    72022.3    72015.8    72965.6   \n",
       "\n",
       "                   1995-05-01 1995-06-01 1995-07-01 1995-08-01 1995-09-01  \\\n",
       "City of London        84409.1    94900.5     110128     112329     104473   \n",
       "Barking & Dagenham    53042.2    53700.3    52113.1    52232.2    51471.6   \n",
       "Barnet                  90258    90107.2    91441.2    92361.3    93273.1   \n",
       "Bexley                63997.1    64252.3    63722.7    64432.6    64509.5   \n",
       "Brent                   73704    74310.5      74127      73547    73789.5   \n",
       "\n",
       "                      ...     2019-06-01 2019-07-01 2019-08-01 2019-09-01  \\\n",
       "City of London        ...         761526     756407     813770     810455   \n",
       "Barking & Dagenham    ...         293889     297426     299421     304778   \n",
       "Barnet                ...         512694     514668     528577     526670   \n",
       "Bexley                ...         339324     338346     337523     333340   \n",
       "Brent                 ...         474821     473849     488784     501533   \n",
       "\n",
       "                   2019-10-01 2019-11-01 2019-12-01 2020-01-01 2020-02-01  \\\n",
       "City of London         826227     776894     737275     757377     765416   \n",
       "Barking & Dagenham     304579     306390     301283     304187     304719   \n",
       "Barnet                 525678     522639     519306     520115     520966   \n",
       "Bexley                 332920     333657     336302     334430     334845   \n",
       "Brent                  494770     432188     427126     424663     471574   \n",
       "\n",
       "                   2020-03-01  \n",
       "City of London         792583  \n",
       "Barking & Dagenham     327136  \n",
       "Barnet                 532569  \n",
       "Bexley                 331679  \n",
       "Brent                  446966  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the head of our new Transposed DataFrame. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City of London', 'Barking & Dagenham', 'Barnet', 'Bexley', 'Brent',\n",
       "       'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield', 'Greenwich',\n",
       "       'Hackney', 'Hammersmith & Fulham', 'Haringey', 'Harrow', 'Havering',\n",
       "       'Hillingdon', 'Hounslow', 'Islington', 'Kensington & Chelsea',\n",
       "       'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton', 'Newham',\n",
       "       'Redbridge', 'Richmond upon Thames', 'Southwark', 'Sutton',\n",
       "       'Tower Hamlets', 'Waltham Forest', 'Wandsworth', 'Westminster',\n",
       "       'Unnamed: 33', 'Inner London', 'Outer London', 'Unnamed: 36',\n",
       "       'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', 'EAST MIDLANDS',\n",
       "       'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST',\n",
       "       'SOUTH WEST', 'Unnamed: 46', 'England'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm what our row indices are, let's call the .index variable on our properties_T DataFrame. \n",
    "properties_T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our suspicion was correct. \n",
    "# Call the .reset_index() method on properties_T to reset the indices, and the reassign the result to properties_T: \n",
    "properties_T = properties_T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=48, step=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check out our DataFrames indices: \n",
    "properties_T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index        NaN 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "0      City of London  E09000001               91449             82202.8   \n",
       "1  Barking & Dagenham  E09000002             50460.2             51085.8   \n",
       "2              Barnet  E09000003             93284.5             93190.2   \n",
       "3              Bexley  E09000004             64958.1             64787.9   \n",
       "4               Brent  E09000005             71306.6             72022.3   \n",
       "\n",
       "  1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "0             79120.7             77101.2             84409.1   \n",
       "1               51269             53133.5             53042.2   \n",
       "2             92247.5             90762.9               90258   \n",
       "3             64367.5             64277.7             63997.1   \n",
       "4             72015.8             72965.6               73704   \n",
       "\n",
       "  1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  \\\n",
       "0             94900.5              110128              112329   \n",
       "1             53700.3             52113.1             52232.2   \n",
       "2             90107.2             91441.2             92361.3   \n",
       "3             64252.3             63722.7             64432.6   \n",
       "4             74310.5               74127               73547   \n",
       "\n",
       "          ...         2019-06-01 00:00:00 2019-07-01 00:00:00  \\\n",
       "0         ...                      761526              756407   \n",
       "1         ...                      293889              297426   \n",
       "2         ...                      512694              514668   \n",
       "3         ...                      339324              338346   \n",
       "4         ...                      474821              473849   \n",
       "\n",
       "  2019-08-01 00:00:00 2019-09-01 00:00:00 2019-10-01 00:00:00  \\\n",
       "0              813770              810455              826227   \n",
       "1              299421              304778              304579   \n",
       "2              528577              526670              525678   \n",
       "3              337523              333340              332920   \n",
       "4              488784              501533              494770   \n",
       "\n",
       "  2019-11-01 00:00:00 2019-12-01 00:00:00 2020-01-01 00:00:00  \\\n",
       "0              776894              737275              757377   \n",
       "1              306390              301283              304187   \n",
       "2              522639              519306              520115   \n",
       "3              333657              336302              334430   \n",
       "4              432188              427126              424663   \n",
       "\n",
       "  2020-02-01 00:00:00 2020-03-01 00:00:00  \n",
       "0              765416              792583  \n",
       "1              304719              327136  \n",
       "2              520966              532569  \n",
       "3              334845              331679  \n",
       "4              471574              446966  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the head() function again on properties_T to check out the new row indices: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            'index',                 NaT, 1995-01-01 00:00:00,\n",
       "       1995-02-01 00:00:00, 1995-03-01 00:00:00, 1995-04-01 00:00:00,\n",
       "       1995-05-01 00:00:00, 1995-06-01 00:00:00, 1995-07-01 00:00:00,\n",
       "       1995-08-01 00:00:00,\n",
       "       ...\n",
       "       2019-06-01 00:00:00, 2019-07-01 00:00:00, 2019-08-01 00:00:00,\n",
       "       2019-09-01 00:00:00, 2019-10-01 00:00:00, 2019-11-01 00:00:00,\n",
       "       2019-12-01 00:00:00, 2020-01-01 00:00:00, 2020-02-01 00:00:00,\n",
       "       2020-03-01 00:00:00],\n",
       "      dtype='object', length=305)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm that our DataFrame's columns are mainly just integers, call the .columns feature on our DataFrame:\n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index        NaN 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "0  City of London  E09000001               91449             82202.8   \n",
       "\n",
       "  1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "0             79120.7             77101.2             84409.1   \n",
       "\n",
       "  1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  \\\n",
       "0             94900.5              110128              112329   \n",
       "\n",
       "          ...         2019-06-01 00:00:00 2019-07-01 00:00:00  \\\n",
       "0         ...                      761526              756407   \n",
       "\n",
       "  2019-08-01 00:00:00 2019-09-01 00:00:00 2019-10-01 00:00:00  \\\n",
       "0              813770              810455              826227   \n",
       "\n",
       "  2019-11-01 00:00:00 2019-12-01 00:00:00 2020-01-01 00:00:00  \\\n",
       "0              776894              737275              757377   \n",
       "\n",
       "  2020-02-01 00:00:00 2020-03-01 00:00:00  \n",
       "0              765416              792583  \n",
       "\n",
       "[1 rows x 305 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the iloc[] method with double square brackets on the properties_T DataFrame, to see the row at index 0. \n",
    "properties_T.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this now. \n",
    "properties_T.columns = properties_T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>E09000001</th>\n",
       "      <th>91448.98487</th>\n",
       "      <th>82202.77314</th>\n",
       "      <th>79120.70256</th>\n",
       "      <th>77101.20804</th>\n",
       "      <th>84409.14932</th>\n",
       "      <th>94900.51244</th>\n",
       "      <th>110128.0423</th>\n",
       "      <th>112329.4376</th>\n",
       "      <th>...</th>\n",
       "      <th>761525.8718</th>\n",
       "      <th>756407.0179</th>\n",
       "      <th>813769.5901</th>\n",
       "      <th>810454.644</th>\n",
       "      <th>826227.062</th>\n",
       "      <th>776894.3978</th>\n",
       "      <th>737275.0265</th>\n",
       "      <th>757376.694</th>\n",
       "      <th>765416.3767</th>\n",
       "      <th>792582.6403</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      City of London  E09000001 91448.98487 82202.77314 79120.70256  \\\n",
       "0      City of London  E09000001       91449     82202.8     79120.7   \n",
       "1  Barking & Dagenham  E09000002     50460.2     51085.8       51269   \n",
       "2              Barnet  E09000003     93284.5     93190.2     92247.5   \n",
       "3              Bexley  E09000004     64958.1     64787.9     64367.5   \n",
       "4               Brent  E09000005     71306.6     72022.3     72015.8   \n",
       "\n",
       "0 77101.20804 84409.14932 94900.51244 110128.0423 112329.4376     ...      \\\n",
       "0     77101.2     84409.1     94900.5      110128      112329     ...       \n",
       "1     53133.5     53042.2     53700.3     52113.1     52232.2     ...       \n",
       "2     90762.9       90258     90107.2     91441.2     92361.3     ...       \n",
       "3     64277.7     63997.1     64252.3     63722.7     64432.6     ...       \n",
       "4     72965.6       73704     74310.5       74127       73547     ...       \n",
       "\n",
       "0 761525.8718 756407.0179 813769.5901 810454.644 826227.062 776894.3978  \\\n",
       "0      761526      756407      813770     810455     826227      776894   \n",
       "1      293889      297426      299421     304778     304579      306390   \n",
       "2      512694      514668      528577     526670     525678      522639   \n",
       "3      339324      338346      337523     333340     332920      333657   \n",
       "4      474821      473849      488784     501533     494770      432188   \n",
       "\n",
       "0 737275.0265 757376.694 765416.3767 792582.6403  \n",
       "0      737275     757377      765416      792583  \n",
       "1      301283     304187      304719      327136  \n",
       "2      519306     520115      520966      532569  \n",
       "3      336302     334430      334845      331679  \n",
       "4      427126     424663      471574      446966  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out our DataFrame again: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a go at this now. \n",
    "properties_T = properties_T.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>E09000001</th>\n",
       "      <th>91448.98487</th>\n",
       "      <th>82202.77314</th>\n",
       "      <th>79120.70256</th>\n",
       "      <th>77101.20804</th>\n",
       "      <th>84409.14932</th>\n",
       "      <th>94900.51244</th>\n",
       "      <th>110128.0423</th>\n",
       "      <th>112329.4376</th>\n",
       "      <th>...</th>\n",
       "      <th>761525.8718</th>\n",
       "      <th>756407.0179</th>\n",
       "      <th>813769.5901</th>\n",
       "      <th>810454.644</th>\n",
       "      <th>826227.062</th>\n",
       "      <th>776894.3978</th>\n",
       "      <th>737275.0265</th>\n",
       "      <th>757376.694</th>\n",
       "      <th>765416.3767</th>\n",
       "      <th>792582.6403</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>81542.6</td>\n",
       "      <td>82382.8</td>\n",
       "      <td>82898.5</td>\n",
       "      <td>82054.4</td>\n",
       "      <td>...</td>\n",
       "      <td>430002</td>\n",
       "      <td>434257</td>\n",
       "      <td>442189</td>\n",
       "      <td>441058</td>\n",
       "      <td>439178</td>\n",
       "      <td>436080</td>\n",
       "      <td>438682</td>\n",
       "      <td>435337</td>\n",
       "      <td>436544</td>\n",
       "      <td>430033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      City of London  E09000001 91448.98487 82202.77314 79120.70256  \\\n",
       "1  Barking & Dagenham  E09000002     50460.2     51085.8       51269   \n",
       "2              Barnet  E09000003     93284.5     93190.2     92247.5   \n",
       "3              Bexley  E09000004     64958.1     64787.9     64367.5   \n",
       "4               Brent  E09000005     71306.6     72022.3     72015.8   \n",
       "5             Bromley  E09000006     81671.5     81657.6     81449.3   \n",
       "\n",
       "0 77101.20804 84409.14932 94900.51244 110128.0423 112329.4376     ...      \\\n",
       "1     53133.5     53042.2     53700.3     52113.1     52232.2     ...       \n",
       "2     90762.9       90258     90107.2     91441.2     92361.3     ...       \n",
       "3     64277.7     63997.1     64252.3     63722.7     64432.6     ...       \n",
       "4     72965.6       73704     74310.5       74127       73547     ...       \n",
       "5     81124.4     81542.6     82382.8     82898.5     82054.4     ...       \n",
       "\n",
       "0 761525.8718 756407.0179 813769.5901 810454.644 826227.062 776894.3978  \\\n",
       "1      293889      297426      299421     304778     304579      306390   \n",
       "2      512694      514668      528577     526670     525678      522639   \n",
       "3      339324      338346      337523     333340     332920      333657   \n",
       "4      474821      473849      488784     501533     494770      432188   \n",
       "5      430002      434257      442189     441058     439178      436080   \n",
       "\n",
       "0 737275.0265 757376.694 765416.3767 792582.6403  \n",
       "1      301283     304187      304719      327136  \n",
       "2      519306     520115      520966      532569  \n",
       "3      336302     334430      334845      331679  \n",
       "4      427126     424663      471574      446966  \n",
       "5      438682     435337      436544      430033  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check out our DataFrame again to see how it looks. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [],
   "source": [
    "# Try this here. \n",
    "properties_T = properties_T.rename(columns = {'Unnamed: 0':'London_Borough', pd.NaT: 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>E09000001</th>\n",
       "      <th>91448.98487</th>\n",
       "      <th>82202.77314</th>\n",
       "      <th>79120.70256</th>\n",
       "      <th>77101.20804</th>\n",
       "      <th>84409.14932</th>\n",
       "      <th>94900.51244</th>\n",
       "      <th>110128.0423</th>\n",
       "      <th>112329.4376</th>\n",
       "      <th>...</th>\n",
       "      <th>761525.8718</th>\n",
       "      <th>756407.0179</th>\n",
       "      <th>813769.5901</th>\n",
       "      <th>810454.644</th>\n",
       "      <th>826227.062</th>\n",
       "      <th>776894.3978</th>\n",
       "      <th>737275.0265</th>\n",
       "      <th>757376.694</th>\n",
       "      <th>765416.3767</th>\n",
       "      <th>792582.6403</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>81542.6</td>\n",
       "      <td>82382.8</td>\n",
       "      <td>82898.5</td>\n",
       "      <td>82054.4</td>\n",
       "      <td>...</td>\n",
       "      <td>430002</td>\n",
       "      <td>434257</td>\n",
       "      <td>442189</td>\n",
       "      <td>441058</td>\n",
       "      <td>439178</td>\n",
       "      <td>436080</td>\n",
       "      <td>438682</td>\n",
       "      <td>435337</td>\n",
       "      <td>436544</td>\n",
       "      <td>430033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      City of London  E09000001 91448.98487 82202.77314 79120.70256  \\\n",
       "1  Barking & Dagenham  E09000002     50460.2     51085.8       51269   \n",
       "2              Barnet  E09000003     93284.5     93190.2     92247.5   \n",
       "3              Bexley  E09000004     64958.1     64787.9     64367.5   \n",
       "4               Brent  E09000005     71306.6     72022.3     72015.8   \n",
       "5             Bromley  E09000006     81671.5     81657.6     81449.3   \n",
       "\n",
       "0 77101.20804 84409.14932 94900.51244 110128.0423 112329.4376     ...      \\\n",
       "1     53133.5     53042.2     53700.3     52113.1     52232.2     ...       \n",
       "2     90762.9       90258     90107.2     91441.2     92361.3     ...       \n",
       "3     64277.7     63997.1     64252.3     63722.7     64432.6     ...       \n",
       "4     72965.6       73704     74310.5       74127       73547     ...       \n",
       "5     81124.4     81542.6     82382.8     82898.5     82054.4     ...       \n",
       "\n",
       "0 761525.8718 756407.0179 813769.5901 810454.644 826227.062 776894.3978  \\\n",
       "1      293889      297426      299421     304778     304579      306390   \n",
       "2      512694      514668      528577     526670     525678      522639   \n",
       "3      339324      338346      337523     333340     332920      333657   \n",
       "4      474821      473849      488784     501533     494770      432188   \n",
       "5      430002      434257      442189     441058     439178      436080   \n",
       "\n",
       "0 737275.0265 757376.694 765416.3767 792582.6403  \n",
       "1      301283     304187      304719      327136  \n",
       "2      519306     520115      520966      532569  \n",
       "3      336302     334430      334845      331679  \n",
       "4      427126     424663      471574      446966  \n",
       "5      438682     435337      436544      430033  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the DataFrame again to admire our good work. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City of London',      'E09000001',      91448.98487,      82202.77314,\n",
       "            79120.70256,      77101.20804,      84409.14932,      94900.51244,\n",
       "            110128.0423,      112329.4376,\n",
       "       ...\n",
       "            761525.8718,      756407.0179,      813769.5901,       810454.644,\n",
       "             826227.062,      776894.3978,      737275.0265,       757376.694,\n",
       "            765416.3767,      792582.6403],\n",
       "      dtype='object', name=0, length=305)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this here. \n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'London_Borough'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'London_Borough'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-659b9720da9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Try this here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclean_properties\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperties_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'London_Borough'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'London_Borough'"
     ]
    }
   ],
   "source": [
    "# Try this here: \n",
    "clean_properties =  pd.melt(properties_T, id_vars= ['London_Borough', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [],
   "source": [
    "# Re-name the column names\n",
    "clean_properties = clean_properties.rename(columns = {0: 'Month', 'value': 'Average_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the DataFrame: \n",
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the .dtypes attribute to check the data types of our clean_properties DataFrame:\n",
    "clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [],
   "source": [
    "# To see if there are any missing values, we should call the count() method on our DataFrame:\n",
    "clean_properties.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [],
   "source": [
    "# Do this here. \n",
    "clean_properties['London_Borough'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset clean_properties on the condition: df['London_Borough'] == 'Unnamed: 34' to see what information these rows contain. \n",
    "clean_properties[clean_properties['London_Borough'] == 'Unnamed: 34'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at how many rows have NAs as their value for ID. \n",
    "# To this end, subset clean_properties on the condition: clean_properties['ID'].isna().\n",
    "# Notice that this line doesn't actually reassign a new value to clean_properties. \n",
    "clean_properties[clean_properties['ID'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your hand at method (1) here: \n",
    "NaNFreeDF1 = clean_properties[clean_properties['Average_price'].notna()]\n",
    "NaNFreeDF1.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we do a count on our new DataFrame, we'll see how many rows we have that have complete information: \n",
    "NaNFreeDF1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data with NaN values\n",
    "NaNFreeDF2 = clean_properties.dropna()\n",
    "NaNFreeDF2.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a count on this DataFrame object: \n",
    "NaNFreeDF2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaNFreeDF2['London_Borough'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the .shape attribute, compare the dimenions of clean_properties, NaNFreeDF1, and NaNFreeDF2: \n",
    "print(clean_properties.shape)\n",
    "print(NaNFreeDF1.shape)\n",
    "print(NaNFreeDF2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of non-boroughs. \n",
    "nonBoroughs = ['Inner London', 'Outer London', \n",
    "               'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', \n",
    "               'EAST MIDLANDS', 'WEST MIDLANDS',\n",
    "              'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST', \n",
    "              'SOUTH WEST', 'England']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this here. \n",
    "NaNFreeDF2[NaNFreeDF2.London_Borough.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaNFreeDF2[~NaNFreeDF2.London_Borough.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaNFreeDF2 = NaNFreeDF2[~NaNFreeDF2.London_Borough.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaNFreeDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do that here. \n",
    "df = NaNFreeDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": [
    "# First of all, make a variable called camden_prices, and assign it the result of filtering df on the following condition:\n",
    "# df['London_Borough'] == 'Camden'\n",
    "camden_prices = df[df['London_Borough'] == 'Camden']\n",
    "\n",
    "# Make a variable called ax. Assign it the result of calling the plot() method, and plugging in the following values as parameters:\n",
    "# kind ='line', x = 'Month', y='Average_price'\n",
    "ax = camden_prices.plot(kind ='line', x = 'Month', y='Average_price')\n",
    "\n",
    "# Finally, call the set_ylabel() method on ax, and set that label to the string: 'Price'. \n",
    "ax.set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": [
    "# Try this yourself. \n",
    "df['Year'] = df['Month'].apply(lambda t: t.year)\n",
    "\n",
    "# Call the tail() method on df\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function 'groupby' will help you to calculate the mean for each year and for each Borough. \n",
    "## As you can see, the variables Borough and Year are now indices\n",
    "dfg = df.groupby(by=['London_Borough', 'Year']).mean()\n",
    "dfg.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reset the index for our new DataFrame dfg, and call the head() method on it. \n",
    "dfg = dfg.head()\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": [
    "# Here's where you should write your function:\n",
    "def create_price_ratio(d):\n",
    "    y1998 = float(d['Average_price'][d['Year']==1998])\n",
    "    y2018 = float(d['Average_price'][d['Year']==2018])\n",
    "    ratio = [y2018/y1998]\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test out the function by calling it with the following argument:\n",
    "# dfg[dfg['London_Borough']=='Barking & Dagenham']\n",
    "create_price_ratio(dfg[dfg['London_Borough']=='Barking & Dagenham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to do this for all of the London Boroughs. \n",
    "# First, let's make an empty dictionary, called final, where we'll store our ratios for each unique London_Borough.\n",
    "final = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's declare a for loop that will iterate through each of the unique elements of the 'London_Borough' column of our DataFrame dfg.\n",
    "# Call the iterator variable 'b'. \n",
    "for b in dfg['London_Borough'].unique():\n",
    "    # Let's make our parameter to our create_price_ratio function: i.e., we subset dfg on 'London_Borough' == b. \n",
    "    borough = dfg[dfg['London_Borough'] == b]\n",
    "    # Make a new entry in the final dictionary whose value's the result of calling create_price_ratio with the argument: borough\n",
    "    final[b] = create_price_ratio(borough)\n",
    "# We use the function and incorporate that into a new key of the dictionary \n",
    "print(final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable called df_ratios, and assign it the result of calling the DataFrame method on the dictionary final. \n",
    "df_ratios = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the head() method on this variable to check it out. \n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All we need to do now is transpose it, and reset the index! \n",
    "df_ratios_T = df_ratios.T\n",
    "df_ratios = df_ratios_T.reset_index()\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just rename the 'index' column as 'London_Borough', and the '0' column to '2018'.\n",
    "df_ratios.rename(columns={'index':'Borough', 0:'2018'}, inplace=True)\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort in descending order and select the top 15 boroughs.\n",
    "# Make a variable called top15, and assign it the result of calling sort_values() on df_ratios. \n",
    "top15 = df_ratios.sort_values(by='2018',ascending=False).head(15)\n",
    "print(top15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the boroughs that have seen the greatest changes in price.\n",
    "# Make a variable called ax. Assign it the result of filtering top15 on 'Borough' and '2018', then calling plot(), with\n",
    "# the parameter kind = 'bar'. \n",
    "ax = top15[['Borough','2018']].plot(kind='bar')\n",
    "\n",
    "ax.set_xticklabels(top15.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
